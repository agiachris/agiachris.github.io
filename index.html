<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
 
  <title>Hi, it's Chris Agia!</title>
  
  <meta name="author" content="Christopher Agia">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ml_icon.png">

  <link rel="stylesheet" type="text/css" href="main.css">
</head>


<script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chris Agia</name>
              </p>
              <p>
              	I am a fourth year <a href="https://engsci.utoronto.ca/explore_our_program/about_engsci/">Engineering Science</a> student at the University of Toronto, majoring in <strong>Robotics Engineering</strong> and minoring in <strong>Business</strong>. I'm in the process of completing my Professional Experience Year (PEY) as an <strong>autonomous systems researcher</strong> at <a href="http://www.noahlab.com.hk/#/home">Huawei Noah's Ark Research Lab</a>, where I work on <strong>deep learning modules for self-driving vehicles</strong>.   
              </p>
              <p>
              	I'm also an active member of <a href="https://www.autodrive.utoronto.ca/about-us">aUToronto</a> (UofT Self-driving Car Group), where I develop state-of-the-art <strong>real-time 3D detection and tracking pipelines</strong> with the Object Detection Team.                  
              </p>
              <p>
              	I enjoy working in team-centric environments as I believe that the best results are achieved through collaboration. I value <strong>work ethic</strong>, <strong>creativity</strong>, and <strong>forward thinking</strong>. 
              </p>
              <p style="text-align:center">
                <a href="mailto:christopher.agia@mail.utoronto.ca">Email</a> &nbsp/&nbsp
                <a href="data/CA_CV_2020.pdf">CV</a> &nbsp/&nbsp
                <a href="data/ChrisAgiaBio.txt">Biography</a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/agiachris/"> LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/agiachris/"> GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/chrisagia_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/chrisagia_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/UofT-Logo.png" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>B.A.Sc in Engineering Science, Robotics Engineering with Business Minor</papertitle>
              <br>
                Faculty of Applied Science and Engineering, University of Toronto 
              <br>
                Expected May 2021 | Toronto, ON
              <p> </p> 
              <em><strong>President's Scholarship Program</strong></em>
              <br>
              <em><strong>NSERC Undergraduate Research Award</strong></em>
              <br>
              <em><strong>Dean's Honour List - Fall 2018, Winter 2019</strong></em>
            </td>
          </tr>
        </tbody></table>


        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research, Publications, and Patents</heading>
              <p>
   				      My research interests lie in the intersection of <strong>Computer Vision</strong>, <strong>Deep Learning</strong>, and <strong>Robotics</strong>. Currently, I am focused on learning-based LiDAR/multi-modal perception, but I also have strong interests in unsupervised learning methods such as <strong>Deep Reinforcement Learning</strong> and <strong>Generative Models</strong>.  
              </p>
              <p>
                My current research role at <a href="http://www.noahlab.com.hk/#/home">Huawei Noah's Ark Lab</a> has given me exposure to topics across the board for intelligent self-driving technology. During my stay, I've had the opportunity to both lead and contribute to projects in several areas including: 3D Semantic Segmentation, Visual Odometry, and Learning-based Localization - much of our work achieving state-of-the-art results in their respective fields. Deployment of our proposed methods to improve overall vehicle autonomy is a goal we all actively work towards. 
              </p>
              <p>
                I also have previous research experience at the <a href="http://asblab.mie.utoronto.ca/">Autonomous Systems and Biomechatronics Lab</a> working under the supervision of <a href="https://www.mie.utoronto.ca/faculty_staff/nejat/">Prof. Goldie Nejat</a>. During my stay, I worked with a team of graduate researchers to investigate the application of Deep Reinforcement Learning for autonomous robot navigation in rough terrain.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/semantic_enhanced.jpeg" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Semantic Enhanced LiDAR-based Localization for Autonomous Driving</papertitle>
              <br>
              Yuan Ren, <a href="https://rancheng.github.io/about/">Ran Cheng</a>, <strong>Christopher Agia</strong>, Bingbing Liu
              <br>
              <em>[Patented], Manuscript in Preparation</em>, 2020.
              <p>We present a novel semantic enhanced LiDAR-based localization algorithm that takes both semantic and non-semantic information into account to promote robustness in estimations and adaptable behvaiour in changing environments. For semantic segmentation, we propose the use of a hybrid model (learning-based + traditional) for the extraction of semantic features.</p>
            </td>
          </tr>
        </tbody></table>

       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/deep_residual_thumb.png" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Deep Residual Pattern Learner for Robust Direct Tracking</papertitle>
              <br>
              <a href="https://rancheng.github.io/about/">Ran Cheng</a>, <strong>Christopher Agia</strong>
              <br>
              <em>Experiments in Progress</em>, 2020.
              <p>We proposed a pipeline to weight residual pattern based on the residual point image local context to simulate the feature encoding and matching process in in-direct approaches. We are aiming to reduce the non-convexity introduced by including original images in energy function.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/road_mask.png" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Point Aggregation with Convolutional CRF for Long-Range Road Segmentation from LiDAR Point Clouds</papertitle>
              <br>
              <strong>Christopher Agia</strong>, <a href="https://rancheng.github.io/about/">Ran Cheng</a>, Yuan Ren, Liu Bingbing
              <br>
              <em>[Patented], Paper in preparation</em>, 2020.
              <p>We propose an end-to-end convolutional network architecture for accurately segmenting road masks at extended ranges from LiDAR point clouds in real-time.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/loam_lidar_odometry.jpeg" alt="clean-usnob" width="140" height="140"> -->
              <img src="images/ddvo_res.gif" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Depth Prediction for Monocular Direct Visual Odometry</papertitle>
              <br>
              <a href="https://rancheng.github.io/about/">Ran Cheng</a>, <strong>Christopher Agia</strong>, David Meger, Gregory Dudek
              <br>
              <em>Paper in preparation</em>, 2020.
              <p>We incorporate dense depth prediction and propose a novel deep learning module to improve the robustness and precision for the traditional Direct Sparse Odometry method.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/robot_nav.png" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Sim2Real: Deep Reinforcement Learning for Autonomous Robot Navigation in Rough Terrain</papertitle>
              <br>
              <a href="https://www.linkedin.com/in/kczhang/?originalSubdomain=ca">Kaicheng Zhang</a>, <a href="https://www.linkedin.com/in/richardhu-12dsf/?originalSubdomain=ca">Han Hu</a>, <a href="https://www.linkedin.com/in/aaron-hao-tan/?originalSubdomain=ca">Aaron Hao Tan</a>, <a href="https://www.linkedin.com/in/michael-ruan-0822/">Michael Ruan</a>, <strong>Christopher Agia</strong>, <a href="https://www.mie.utoronto.ca/faculty_staff/nejat/"> Goldie Nejat</a>
              <br>
              <em>Manuscript in preparation</em>, 2020.
              <p>We use Deep Reinforcement Learning with Transfer Learning techniques to approach the Sim2Real challenge, enabling a robot to learn suitable navigation behaviour for rough terrain.</p>
            </td>
          </tr>
        </tbody></table>

        


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Work Experience</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/google_logo.png" alt="clean-usnob" width="120" height="120">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Incoming - Software Engineering Intern</papertitle>
              <br>
                <a href="https://about.google/">Google </a>, Geo Search Team - HQ | <a href="https://www.blog.google/technology/next-billion-users/">Next Billion Users</a> 
              <br>
                <strong>Summer 2020</strong> | Mountain View, CA
              <p> 
                Designing machine learning models to handle geographically tagged queries. 
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/autoronto_logo.png" alt="clean-usnob" width="120" height="120">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Computer Vision Engineer</papertitle>
              <br>
                <a href="https://www.autodrive.utoronto.ca/about-us">aUToronto</a>, Object Detection Team | <a href="https://www.sae.org/attend/student-events/autodrive-challenge/">SAE/GM Autodrive Challenge </a> 
              <br>
                Aug 2019 - <strong>Present</strong> | Toronto, ON
              <p> 
              	Developing a state-of-the-art deep learning pipeline for real-time 3D detection and tracking of vehicles, pedestrians and cyclists from multiple sensor input. 
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/huawei_logo.jpg" alt="clean-usnob" width="120" height="120">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Autonomous Systems Research Intern</papertitle>
              <br>
                Huawei Technologies, <a href="http://www.noahlab.com.hk/#/home">Noah's Ark Research Lab</a>
              <br>
                May 2019 - <strong>Present</strong> | Toronto, ON
              <p> 
              	Research and development for autonomous systems (self-driving technology). Current research areas: semantic segmentation from LiDAR point clouds, road estimation, visual odometry, depth estimation, and learning-based localization. 
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/UofT-Crest-Square.png" alt="clean-usnob" width="120" height="120">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Undergraduate Researcher</papertitle>
              <br>
                University of Toronto, <a href="http://asblab.mie.utoronto.ca/">Autonomous Systems and Biomechatronics Lab</a> 
              <br>
                May 2018 - Aug 2018 | Toronto, ON
              <p> 
              	Search and rescue robotics - research on the topics of Deep Reinforcement Learning and Transfer Learning for autonomous robot navigation in rough and hazardous terrain. ROS (Robot Operating System) software development for various mobile robots.
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ge_logo.jpg" alt="clean-usnob" width="120" height="120">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Software Engineering Intern</papertitle>
              <br>
                General Electric, <a href="https://www.gegridsolutions.com/index.htm">Grid Solutions</a>
              <br>
                May 2017 - Aug 2017 | Markham, ON
              <p> 
              	Created customer-end software tools used to accelerate the transition/setup process of new protection and control systems upon upgrade. Designed the current Install-Base and Firmware Revision History databases used by GE internal service teams.
              </p> 
            </td>
          </tr>
        </tbody></table>




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects and Competitions</heading>
              <p>
                <strong>Learn by doing</strong> - I've had the opportunity to work on many interesting projects that range across industries such as Robotics, Health Care, Finance, Transportation, and Logistics.  
              <p>
              	Links to the source code are embedded in the project titles.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/aer201.png" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/agiachris/AER201-Microcontroller">
              	<papertitle>Autonomous Packing Robot</papertitle>
          	  </a>
              <br>
                University of Toronto, AER201 Robot Competition
              <p> 
              	Designed, built, and programmed a robot that systematically sorts and packs up to 50 pills/minute to assist those suffering from dimentia. An efficient user interface was created to allow a user to input packing instructions. <strong><em> Team placed 3rd/50.</em></strong> <a href="https://drive.google.com/file/d/1wl2uyzpLt61S0hzdNPHVLlGFJeSz2zRs/view?usp=sharing">Detailed project documentation</a> / <a href="https://www.youtube.com/watch?v=iv9r8VIvHpQ">Youtube video</a>
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cec.png" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/kimwoo11/cec2019">
              	<papertitle>Automated Robotic Garbage Collection</papertitle>
          	  </a>
              <br>
                Canadian Engineering Competition 2019, Programming Challenge
              <p> 
              	Based on the robotics <a href="https://en.wikipedia.org/wiki/Sense_Plan_Act">Sense-Plan-Act Paradigm</a>, we created an AI program to handle high-level (path planning, goal setting) and low-level (path following, object avoidance, action execution) tasks for an automated waste collection system to be used in fast food restaurants. <strong><em>4th place Canada.</em></strong> <a href="https://drive.google.com/file/d/1rYYnvsim5CcmZjdqTi77GO5-5UgTqhUc/view?usp=sharing">Presentation </a>
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/oec_logo.jpg" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/kimwoo11/oec2019">
              	<papertitle>Hospital Triage System</papertitle>
              </a>
              <br>
                Ontario Engineering Competition 2019, Programming Challenge
              <p> 
              	Developed a machine learning software solution to predict the triage score of emergency patients, allocate available resources to patients, and track key hospital performance metrics to reduce emergency wait times. <strong><em>1st place Ontario.</em></strong> <a href="https://drive.google.com/file/d/131vm1maZUMwwmfP15GKlHtS03BRCOEMn/view?usp=sharing">Presentation</a> / <a href="images/oec_team.jpg">Team photo</a>
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/utek_logo.png" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/kimwoo11/utek2019">
              	<papertitle>Warehouse Logistics Planning</papertitle>
              </a>
              <br>
                UTEK Engineering Competition 2019, Programming Challenge
              <p> 
              	Created a logistics planning algorithm that assigned mobile robots to efficiently retrieve warehouse packages. Our solution combined traditional algorithms such as A* Path Planning with heuristic-based clustering. <strong><em>1st place UofT.</em></strong> <a href="https://drive.google.com/file/d/1ZynKLH1kdHOEQr2_tRnss4r-cF7ILf8S/view?usp=sharing">Presentation</a> / <a href="images/utek_team.jpg">Team photo</a>
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mie438.png" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Smart Intersection - Yonge and Dundas</papertitle>
              <br>
                University of Toronto, MIE438 Robot Design
              <p> 
              	We propose a traffic intersection model which uses computer vision to estimate lane congestion and manage traffic flow accordingly. A mockup of our proposal was fabricated to display the behaviour and features of our system.<a href="https://drive.google.com/file/d/10SHGcUwMIGsUryGMhp0yHSlfHsys0UA0/view?usp=sharing"> Detailed report </a> / <a href="https://www.youtube.com/watch?v=fOmKNn2y-C4">YouTube video </a> 
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cibc_logo.png" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/agiachris/CIBC-Hackathon">
              	<papertitle>Insurance Fraud Detection</papertitle>
              </a>
              <br>
                CIBC Data Studio Hackathon, Programming Challenge
              <p> 
              	Developed an unsupervised learning system utilizing Gaussian Mixture Models to identify insurance claim anomalies for CIBC.
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bluesky_logo.jpg" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/agiachris/Solar-Array-Simulator">
              	<papertitle>Solar Array Simulation</papertitle>
              </a>
              <br>
                Blue Sky Solar Racing, Strategic Planning Team
              <p> 
              	Created a simulator that ranks the performance of any solar array CAD model by predicting the instantaneous energy generated under various daylight conditions. 
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gomoku.png" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/agiachris/Gomoku-AI-Engine">
              	<papertitle>Gomoku AI Engine</papertitle>
              </a>
              <br>
                University of Toronto, Class Competition
              <p> 
              	Developed an AI program capable of playing Gomoku against both human and virtual opponents. The software's decision making process is determined by experimentally tuned heuristics which were designed to emulate that of a human opponent. 
              </p> 
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/semsim.png" alt="clean-usnob" width="100" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/agiachris/Semantic-Similarity">
              	<papertitle>Word Pairing - Semantic Similarity</papertitle>
              </a>
              <br>
                University of Toronto, Class Competition
              <p> 
              	Programmed an intelligent system that approximates the semantic similarity between any two pair of words by parsing data from large novels and computing cosine similarities and Euclidean spaces between vector descriptors of each word.
              </p> 
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>



  <div id="particles-js"></div>
  <script>
      particlesJS.load("particles-js", "particles_config/particlesjs-config.json",
      function(){
          console.log("particles.json loaded...")
      })
  </script>



</body>
</html>
